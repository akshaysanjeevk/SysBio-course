\documentclass{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{amsmath}
\title{An Analysis on Public Health Data of Chronic Kidney Disease}
\author{Akshay Sanjeev}
\date{\today}

\begin{document}
\maketitle

\section{Motivation}
\subsection{Notation and Convention}
By standard dataset, from now on I will be referring to the following data structure. 
We have $m$ independent variables(a.k.a features), denoted by $x^i, i = 1,2,3, \cdots,m$ 
and one dependent variable(a.k.a label), $m$. Let $n$ be the total number of observations, 
and the lower index denotes the observation. Thus the dataset is set like the one given below. 
\begin{equation}
    \begin{pmatrix}
        x^1_1 & x^2_1 & \cdots & x^m_1 & y_1 \\
        x^1_2 & x^2_2 & \cdots & x^m_2 & y_2 \\
        \vdots & \vdots & \ddots & \vdots & \vdots \\
        x^1_n & x^2_n & \cdots & x^m_n & y_n
    \end{pmatrix}
\end{equation}



\section{Pre-Processing Data}

\section{Decision Tree}
\subsection{Informal Description}
A decision tree is a supervised learning method, where you split data based 
on a nested \texttt{if} \texttt{else} conditions. To build a decision tree, take the 
standard dataset,

\section{Random Forest}
\subsection{Informal Description}


\section{Feed-forward Neural Network}
\subsection{Informal Description}


\end{document}